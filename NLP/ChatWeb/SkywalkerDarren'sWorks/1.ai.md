---
layout: default
title: ai.py
parent: SkywalkerDarren
grand_parent: chatWeb的裝置與應用
nav_order: 1
date: 2023-11-04
last_modified_date: 2023-11-04 04:58:00
tags: AI chat
---

# ai.py 程式說明
{: .no_toc }

<details open markdown="block">
  <summary>
    Table of contents
  </summary>
  {: .text-delta }
- TOC
{:toc}
</details>
---

## 背景

## 程式說明

### 重要函數

*以下主要由chatGPT生成、斜線部分為本人意見增修*

這段[程式碼](./ai.py)提供了一個名為 `AI` 的類別，用於將自然語言處理的能力整合到一個Python對象中。該類別使用了多種 API，包括 OpenAI、tiktoken 和 sklearn 中的 [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) 和 [cosine_similarity](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html)。

以下是類別中一些重要函數的用途、參數和輸出：

1. `__init__(self, cfg: Config)`:
   - 用途：建構函數，用於初始化 AI 類別。
   - 參數：
     - `cfg` - 一個包含配置資訊的 
     - `Config` 類別實例。
   - 輸出：沒有返回值，但會初始化類別的屬性。

2. `_chat_stream(self, messages: list[dict], use_stream: bool = None) -> str`:
   - 用途：進行與 OpenAI 交談模型的溝通，根據輸入訊息獲得回應。
   - 參數：
     - `messages` - 包含要傳遞給模型的消息的字典列表；
     - `use_stream` - 一個布林值，指示是否使用流模式。
   - 輸出：一個字符串，代表 AI 的回應。

3. `completion(self, query: str, context: list[str])`:
   - 用途：創建一個根據給定上下文和用戶查詢生成的完成文本、*用以控制GTP產出的品質*。
   - 參數：
     - `query` - 用戶的查詢文本；
     - `context` - 一個字符串列表，包含與查詢相關的上下文。
   - 輸出：AI 根據上下文生成的回應。

4. `get_keywords(self, query: str) -> str`:
   - 用途：從用戶的查詢中提取關鍵字。
   - 參數：`query` - 用戶的查詢文本。
   - 輸出：一個由逗號分隔的關鍵字字符串。

5. `create_embedding(text: str) -> (str, list[float])`:
   - 用途：為提供的文本創建一個嵌入表示(embedding)。
   - 參數：`text` - 要創建嵌入表示的文本。
   - 輸出：一對值，第一個是原始文本，第二個是文本的嵌入表示列表。

6. `generate_summary(self, embeddings, num_candidates=3, use_sif=False)`:
   - 用途：為提供的嵌入表示生成一個摘要。
   - 參數：
     - `embeddings` - 嵌入表示的列表；
     - `num_candidates` - 生成摘要的候選數量；
     - `use_sif` - 是否使用平滑逆文檔頻率(SIF)。
   - 輸出：一個文本摘要。

這個類別使用了 OpenAI 的 GPT-3 模型進行語言生成，並通過其 `ChatCompletion` 和 `Embedding` API 實現這一功能。此外，該類別還使用了一些 NLP 技術，如 TF-IDF 和余弦相似度，來分析文本並生成摘要。

## 其他函數

*前述chatGPT忽略掉的函數，可能涉及重要設定及影響，補充如下*

### _num_tokens_from_string

這個 `_num_tokens_from_string` 方法的用途是計算給定文本字符串中的 tokens（代幣）數量。

- **用途**：測量給定字符串的 token 數，這對於與基於 token 的系統（如 OpenAI API）交互時預測使用成本和限制很有用。
  
- **參數**：`string` - 需要計算 token 數的文本字符串。

- **輸出**：返回一個整數，表示字符串中的 token 數量。

### _cut_texts

*token最大上限值將在此處設定。如果更換模型，需配合修改此值。*

這個 `_cut_texts` 方法的用途是裁剪一個文本列表，使其總 token 數量不超過一個特定的最大限制。

- **用途**：在發送到 token 數量有限制的 API（例如 OpenAI）之前，將文本列表修剪到可接受的 token 數量範圍內。

- **參數**：`context` - 一個字符串列表，每個字符串代表一段文本。

- **輸出**：返回一個經過修剪的字符串列表，其中的總 token 數量不會超過所設定的最大限制（在此例中為 3072 tokens，計算方式為 4096 - 1024）。如果總數超出限制，則從列表中移除多餘的文本，只保留能夠符合最大 token 限制的文本片段。

## 重要設定

### init中的模型名稱

```python
    def __init__(self, cfg: Config):
...
        self._encoding = tiktoken.encoding_for_model('gpt-3.5-turbo')
```

### complete 內文

此內文將會控制chatGPT的行為、人設為期刊助理。將就其表現進行必要的檢討修正。原文：

```python
'content': f'You are a helpful AI article assistant. '
          f'The following are the relevant article content fragments found from the article. '
          f'The relevance is sorted from high to low. '
          f'You can only answer according to the following content:\n```\n{text}\n```\n'
          f'You need to carefully consider your answer to ensure that it is based on the context. '
          f'If the context does not mention the content or it is uncertain whether it is correct, '
          f'please answer "Current context cannot provide effective information."'
          f'You must use {self._language} to respond.'},
```


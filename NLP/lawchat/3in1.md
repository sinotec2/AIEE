---
layout: default
title: ä¸‰åˆä¸€å¼•æ“
parent: lawchat
grand_parent: è‡ªç„¶èªè¨€è™•ç†
nav_order: 99
date: 2024-05-03
last_modified_date: 2024-05-07 11:58:34
tags: AI chat
---
åœ¨æ³•å¾‹æ–‡ä»¶çš„ RAGï¼ˆRetrieval-Augmented Generationï¼‰ç³»çµ±ä¸­ï¼Œå¦‚ä½•å»ºç«‹ **indexï¼ˆç´¢å¼•ï¼‰** æ˜¯æ±ºå®šæª¢ç´¢æ•ˆæœèˆ‡æœ€çµ‚ç”Ÿæˆå“è³ªçš„æ ¸å¿ƒä¹‹ä¸€ã€‚ç”±æ–¼æ³•å¾‹æ–‡ä»¶é€šå¸¸ç¯‡å¹…é•·ã€ç”¨è©åš´è¬¹ã€çµæ§‹æ¸…æ™°ï¼Œå»ºç«‹ index æ™‚éœ€ç‰¹åˆ¥è€ƒæ…®èªç¾©çš„æº–ç¢ºæ€§ã€ä¸Šä¸‹æ–‡çš„å®Œæ•´æ€§èˆ‡æª¢ç´¢çš„æ•ˆç‡ã€‚

ä¸‹é¢æ˜¯ä¸€äº› **æ³•å¾‹æ–‡ä»¶ä¸­æœ€ä½³çš„ Indexing ç­–ç•¥èˆ‡å»ºè­°**ï¼š

---

## ğŸ“Œ ä¸€ã€åˆ†æ®µï¼ˆChunkingï¼‰ç­–ç•¥

### âœ… **æœ€ä½³é¸æ“‡ï¼šåŸºæ–¼çµæ§‹çš„åˆ†æ®µ**

æ³•å¾‹æ–‡ä»¶é€šå¸¸æœ‰æ˜ç¢ºçš„çµæ§‹ï¼ˆå¦‚æ¢æ¬¾ã€ç¯€ã€ç« ï¼‰ï¼Œä¾‹å¦‚ï¼š

- ç¬¬1ç«  ç¸½å‰‡
    
- ç¬¬2æ¢ åˆåŒæˆç«‹
    
- ç¬¬3æ¢ ç•¶äº‹äººç¾©å‹™
    

**åšæ³•ï¼š**

- åˆ©ç”¨æ­£å‰‡è¡¨é”å¼æå–é€™äº›çµæ§‹ï¼ˆå¦‚ï¼š`ç¬¬[ä¸€äºŒä¸‰å››äº”\d]+[ç« æ¢ç¯€]`ï¼‰
    
- æ¯ä¸€æ®µ chunk ç‚ºä¸€å€‹ index entryï¼Œä¿ç•™å…¶åŸå§‹æ¨™é¡Œèˆ‡å…§å®¹
    
- åŠ å…¥å…ƒè³‡æ–™ï¼šæ¢æ–‡è™Ÿã€æ–‡ä»¶åç¨±ã€æ—¥æœŸç­‰
    

**å„ªé»ï¼š**

- èªç¾©å®Œæ•´ã€ç„¡æˆªæ–·
    
- å®¹æ˜“è¿½è¹¤ä¾†æºèˆ‡å¯è§£é‡‹æ€§é«˜
    

---

### âŒ **ä¸å»ºè­°ï¼šå›ºå®š token æ•¸ chunkingï¼ˆä¾‹å¦‚æ¯ 500 tokensï¼‰**

- å®¹æ˜“é€ æˆèªç¾©æˆªæ–·ï¼ˆå°¤å…¶æ³•å¾‹é‚è¼¯è¤‡é›œï¼Œæ¢æ–‡ä¹‹é–“æœ‰ä¾è³´ï¼‰
    
- é›£ä»¥å›æº¯ä¾†æºæ¢æ–‡ï¼Œé™ä½å¯ä¿¡åº¦
    

---

## ğŸ“Œ äºŒã€åµŒå…¥ï¼ˆEmbeddingï¼‰æ¨¡å‹é¸æ“‡

### âœ… æ¨è–¦æ¨¡å‹ï¼š

- **æ³•å¾‹å°ˆç”¨åµŒå…¥æ¨¡å‹**ï¼ˆå¦‚ï¼š`intfloat/e5-base-v2`, `sentence-transformers/all-mpnet-base-v2`ï¼‰
    
- **ä¸­æ–‡æ³•å¾‹å ´æ™¯ï¼š** å¯ç”¨ Chinese Legal-BERT æˆ–è¨“ç·´åµŒå…¥æ¨¡å‹ï¼ˆå¦‚èˆ‡ `Lawformer` é…åˆï¼‰
    

### âœ… åµŒå…¥å…§å®¹å»ºè­°ï¼š

- æ¢æ–‡ + æ¨™é¡Œ + ä¸Šä¸‹æ–‡æ‘˜è¦
    
- åŠ å…¥æ¬„ä½å¦‚ã€æ–‡ä»¶é¡å‹ã€‘ã€é ’å¸ƒæ©Ÿæ§‹ã€‘ã€ç”Ÿæ•ˆæ—¥æœŸã€‘ç­‰ metadataï¼Œæé«˜æª¢ç´¢çš„é‡å°æ€§
    

---

## ğŸ“Œ ä¸‰ã€å‘é‡ç´¢å¼•å·¥å…·é¸æ“‡

### å¸¸è¦‹å‘é‡è³‡æ–™åº«ï¼š

- **FAISS**ï¼ˆå¿«é€Ÿã€æœ¬åœ°éƒ¨ç½²ï¼‰
    
- **Weaviate**ï¼ˆæ”¯æ´ metadata filterï¼‰
    
- **Qdrant / Milvus**ï¼ˆé«˜æ€§èƒ½ã€å¤§è¦æ¨¡ï¼‰
    

å°æ–¼**æ³•å¾‹æ–‡ä»¶çš„å¯¦å‹™æ‡‰ç”¨**ï¼Œå»ºè­°ç”¨ï¼š

- **Hierarchical Index + Metadata filter**
    
    - æ¯”å¦‚ï¼šå…ˆæ ¹æ“šã€æ–‡ä»¶åç¨±ã€‘ã€æ¢æ–‡ç« ç¯€ã€‘ç¯©é¸ â†’ å†å‘é‡æª¢ç´¢ â†’ å† rerank
        

---

## ğŸ“Œ å››ã€Retrieval çµåˆ Ranker

å–®é  semantic embedding å¸¸å¸¸ä¸è¶³ä»¥æ’å‡ºæœ€ç›¸é—œçš„æ¢æ–‡ã€‚

### æœ€ä½³å¯¦è¸ï¼š

- **Hybrid retrieval**ï¼š
    
    - çµåˆ dense vectorï¼ˆèªç¾©ï¼‰+ BM25ï¼ˆå­—é¢åŒ¹é…ï¼‰é›™å¼•æ“
        
    - ä¾‹å¦‚ï¼šå…ˆç”¨ BM25 ç¸®å°ç¯„åœï¼Œå†ç”¨å‘é‡ rerank
        
- **åŠ  rerankerï¼ˆå¦‚ BGE-Rerankerï¼‰é€²è¡Œèªç¾©æ’åº**
    
    - å¯é¡¯è‘—æå‡æº–ç¢ºç‡èˆ‡ç”Ÿæˆè³ªé‡
        

---

## ğŸ“Œ äº”ã€åŠ å…¥ Prompt-aware chunkingï¼ˆå¯é¸é€²éšï¼‰

å¦‚æœç›®æ¨™å•é¡Œåå¥½æå–å…·é«”ç­”æ¡ˆï¼ˆå¦‚â€œæŸæ¢æ³•å¾‹æ˜¯å¦è¦å®šäº† xxxâ€ï¼‰ï¼Œå¯ä»¥è€ƒæ…®ï¼š

- å°‡åŸå§‹ chunk èˆ‡â€œå¯èƒ½å•é¡Œâ€ç”Ÿæˆ QA-pair åŠ å…¥ index
    
- å¢åŠ æª¢ç´¢çš„å•é¡Œ-ç­”æ¡ˆå°é½Šèƒ½åŠ›ï¼ˆå³ Dense Passage Retrievalï¼‰
    

---

## âœ… ç¸½çµï¼šæ³•å¾‹æ–‡ä»¶ RAG Index å»ºè­°æ–¹æ¡ˆ

|é …ç›®|å»ºè­°|
|---|---|
|Chunk æ–¹æ³•|åŸºæ–¼æ¢æ–‡ã€ç« ç¯€åˆ†æ®µï¼ˆçµæ§‹åŒ– chunkï¼‰|
|Embedding|æ³•å¾‹é ˜åŸŸå°ˆç”¨åµŒå…¥æ¨¡å‹ï¼ˆä¸­è‹±æ–‡å€åˆ†ï¼‰|
|Metadata|æ¢è™Ÿã€æ¨™é¡Œã€æ³•å¾‹åç¨±ã€ç”Ÿæ•ˆæ—¥æœŸã€æ©Ÿæ§‹|
|Vector DB|FAISS / Qdrant / Weaviate + metadata filter|
|æª¢ç´¢ç­–ç•¥|Hybridï¼ˆå‘é‡ + BM25ï¼‰+ reranker|
|ç‰¹æ®Šéœ€æ±‚|å¯åŠ å…¥ QA pair æˆ–æ‘˜è¦ç´¢å¼•ä½œè¼”åŠ©|

---

å¦‚ä½ æœ‰å…·é«”çš„æ³•å¾‹æ–‡ä»¶æ¨£æœ¬ï¼ˆä¾‹å¦‚æŸåœ‹çš„æ°‘æ³•ã€åˆåŒæ¨£æ¿ï¼‰ï¼Œæˆ‘ä¹Ÿå¯ä»¥å”åŠ©ä½ è¨­è¨ˆä¸€å€‹å…·é«”çš„ chunking/embedding/index pipelineã€‚æ˜¯å¦éœ€è¦æˆ‘å¹«ä½ è¨­è¨ˆä¸€å€‹åˆæ­¥çš„ demo pipelineï¼Ÿ
# ä¸‰åˆä¸€å¼•æ“
{: .no_toc }

<details open markdown="block">
  <summary>
    Table of contents
  </summary>
  {: .text-delta }
- TOC
{:toc}
</details>
---

## ç›®æ¨™

ä½ é€™å€‹åšæ³•ã€Œå°‡æ¢æ–‡å…§å®¹ã€æ‘˜è¦èˆ‡é—œéµè©åˆ†é–‹ embedã€å…¶å¯¦æ˜¯éå¸¸åˆç†çš„ç­–ç•¥ï¼Œå°æ–¼ç´°ç¯€æª¢ç´¢èˆ‡èªç¾©ç†è§£éƒ½æœ‰å¹«åŠ©ã€‚ä½†ç‚ºäº†è®“ `query_engine` æˆ– `chat_engine` èƒ½æ­£ç¢ºæ•´åˆé€™äº›è³‡è¨Šï¼Œæœ‰å¹¾å€‹åšæ³•èˆ‡å»ºè­°å¯ä»¥åƒè€ƒï¼Œä¸‹é¢æˆ‘ä¾ç…§ä½ æåˆ°çš„ã€Œå¦‚ä½•æ•´åˆã€èˆ‡ã€Œæ˜¯å¦éœ€è¦æ§åˆ¶åˆ†æµã€é€™å…©é»ä¾†èªªæ˜ï¼š

---

### 1. **ä¸‰ç¨®è³‡è¨Šåˆ†åˆ¥åµŒå…¥ï¼Œä½†å±¬æ–¼åŒä¸€ Nodeï¼Œä¸¦ç”¨ metadata å€åˆ†**

é€™æ˜¯æœ€å¸¸è¦‹çš„åšæ³•ï¼š  
ä½ å¯ä»¥å°æ–¼åŒä¸€æ¢æ³•è¦ï¼Œå»ºç«‹ä¸‰å€‹ nodeï¼Œæ¯å€‹ node ä»£è¡¨ä¸€ç¨®å…§å®¹ï¼ˆæ¢æ–‡åŸæ–‡ / æ‘˜è¦ / é—œéµè©ï¼‰ï¼Œåœ¨ metadata ä¸­åŠ å…¥ `type: æ¢æ–‡`ã€`type: æ‘˜è¦`ã€`type: é—œéµè©`ã€‚

**ç¯„ä¾‹ metadataï¼š**

```json
{
  "æ¯æ³•åç¨±": "æ°´æ±¡æŸ“é˜²æ²»æ³•",
  "å­æ³•åç¨±": "æ”¾æµæ°´æ¨™æº–",
  "æ¢": "ç¬¬5æ¢",
  "type": "æ‘˜è¦"
}
```

---

### 2. **è®“ retriever æŒ‰ç…§ type é€²è¡Œç¯©é¸èˆ‡æ’åºï¼ˆå¯åŠ åˆ†æµï¼‰**

ä½ å¯ä»¥åœ¨ `retriever` æˆ– `query_engine` ä½¿ç”¨ `filters` ä¾†æŒ‡å®šåªæŸ¥è©¢å“ªä¸€é¡å‹çš„å…§å®¹ã€‚ä¾‹å¦‚ï¼š

```python
retriever = vector_index.as_retriever(filters=MetadataFilters(filters=[
    ExactMatchFilter(key="type", value="æ¢æ–‡")
]))
```

æˆ–è€…ï¼šå»ºç«‹å¤šå€‹ retrieverï¼š

- `law_text_retriever`
- `summary_retriever`
- `keywords_retriever`

ç„¶å¾Œç”¨è‡ªè¨‚çš„ `query_router` æˆ– `query_analyzer` ä¾†æ±ºå®šè©²æŠŠ query å°å»å“ªä¸€å€‹ retrieverã€‚

---

### 3. **é€²éšï¼šå»ºç«‹ä¸€å€‹è‡ªè¨‚çš„ RouterQueryEngine**

å¦‚æœä½ ä½¿ç”¨ `llama_index` çš„ `RouterQueryEngine`ï¼Œå¯ä»¥æ ¹æ“šä½¿ç”¨è€… query ä¸­çš„èªæ„è‡ªå‹•é¸æ“‡é©åˆçš„ retrieverï¼š

```python
from llama_index.query_engine.router_query_engine import RouterQueryEngine
from llama_index.selectors import LLMSingleSelector

query_engine = RouterQueryEngine(
    selector=LLMSingleSelector.from_defaults(),
    query_engine_tools=[
        QueryEngineTool.from_defaults(query_engine=law_text_engine, description="æŸ¥è©¢æ¢æ–‡"),
        QueryEngineTool.from_defaults(query_engine=summary_engine, description="æŸ¥è©¢æ‘˜è¦"),
        QueryEngineTool.from_defaults(query_engine=keyword_engine, description="æŸ¥è©¢é—œéµè©")
    ]
)
```

---

### 4. **æ˜¯å¦åˆä½µåµŒå…¥ï¼Ÿ**

å¦ä¸€ç¨®é¸æ“‡æ˜¯ï¼šå°‡æ¢æ–‡ã€æ‘˜è¦èˆ‡é—œéµè©åˆä½µç‚ºåŒä¸€ node çš„ `text`ï¼Œé€™æ¨£å°±åªéœ€è¦ä¸€å€‹ embeddingï¼Œä½†ä½ å°±å¤±å»äº†ç´°éƒ¨æ§åˆ¶èˆ‡ä¾†æºåˆ¤åˆ¥çš„å½ˆæ€§ï¼š

```python
node_text = f"æ¢æ–‡ï¼š{law_text}\næ‘˜è¦ï¼š{summary}\né—œéµè©ï¼š{keywords}"
```

---

### çµè«–æ•´ç†ï¼š

| ä½œæ³• | å„ªé» | ç¼ºé» |
|------|------|------|
| åˆ†ä¸‰å€‹ nodeï¼Œmetadata æ¨™æ˜ type | æ˜“æ§åˆ¶ã€å¯æŸ¥è©¢ä¸åŒé¢å‘ | å¤šç­†è³‡æ–™ï¼Œéœ€åˆ†é¡ |
| åŒä¸€ node åˆä½µ text | å»ºç«‹æ–¹ä¾¿ã€embedding ç°¡å–® | ç„¡æ³•åˆ†æµæŸ¥è©¢ï¼Œå½ˆæ€§å·® |
| å¤šå€‹ retriever + Router | ç²¾æº–åˆ†æµï¼Œæ”¯æ´ä¸åŒå•æ³• | å¯¦ä½œç¨è¤‡é›œï¼Œä½†éˆæ´» |

---

å¦‚æœä½ æƒ³ï¼Œæˆ‘å¯ä»¥å¹«ä½ ä¾ç…§ä½ ç›®å‰çš„ embedding çµæ§‹ï¼Œè¨­è¨ˆ retriever è·¯ç”±é‚è¼¯æˆ–æ˜¯ metadata çµæ§‹ã€‚ä½ å¸Œæœ›ä½¿ç”¨å“ªä¸€ç¨®æ•´åˆæ–¹å¼å‘¢ï¼Ÿï¼ˆåˆ† node + åˆ†æµã€é‚„æ˜¯åˆä½µ nodeï¼Ÿï¼‰

## Routeræ–¹æ¡ˆ

å¤ªå¥½äº†ï¼æˆ‘é€™é‚Šå…ˆå¹«ä½ åšä¸€å€‹ç°¡å–®ã€å¯æ“´å……çš„æ¨¡çµ„åŒ–ç¯„ä¾‹æ¶æ§‹ï¼Œæ­é… `Streamlit`ï¼Œè®“ä½ èƒ½ï¼š

1. åŒ¯å…¥ä¸‰çµ„è³‡æ–™ï¼ˆæ¢æ–‡ã€æ‘˜è¦ã€é—œéµè©ï¼‰  
2. å„è‡ªå»ºç«‹ index èˆ‡ retriever  
3. é€é `RouterQueryEngine` è‡ªå‹•åˆ†æµå›ç­”  
4. ç”¨ç°¡å–®çš„ç¶²é ä»‹é¢è¼¸å…¥æŸ¥è©¢æŒ‡ä»¤ã€å¾—åˆ°å›æ‡‰  

---

### âœ… æª”æ¡ˆçµæ§‹å»ºè­°ï¼š

```
law_query_demo/
â”œâ”€â”€ app.py                  # Streamlit ä¸»ç¨‹å¼
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ laws.json
â”‚   â”œâ”€â”€ summaries.json
â”‚   â””â”€â”€ keywords.json
â”œâ”€â”€ index_builder.py        # index å»ºç«‹èˆ‡è¼‰å…¥
â”œâ”€â”€ router_engine.py        # RouterQueryEngine åˆå§‹åŒ–
â””â”€â”€ utils.py                # å…¬ç”¨å·¥å…·
```

---

### âœ… `index_builder.py`

```python
from llama_index.core import VectorStoreIndex, Document

def load_documents(json_path):
    import json
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return [Document(text=item["text"]) for item in data]

def build_index(json_path):
    docs = load_documents(json_path)
    return VectorStoreIndex.from_documents(docs)
```

---

### âœ… `router_engine.py`

```python
from llama_index.core.query_engine import RetrieverQueryEngine
from llama_index.core.query_engine.router_query_engine import RouterQueryEngine, QueryEngineTool
from llama_index.core.selectors import LLMSingleSelector
from index_builder import build_index

def init_router_engine():
    law_index = build_index("data/laws.json")
    summary_index = build_index("data/summaries.json")
    keyword_index = build_index("data/keywords.json")

    law_engine = law_index.as_query_engine(similarity_top_k=3)
    summary_engine = summary_index.as_query_engine(similarity_top_k=3)
    keyword_engine = keyword_index.as_query_engine(similarity_top_k=3)

    tools = [
        QueryEngineTool.from_defaults(law_engine, description="æŸ¥è©¢å®Œæ•´æ³•æ¢åŸæ–‡"),
        QueryEngineTool.from_defaults(summary_engine, description="æŸ¥è©¢æ³•æ¢æ‘˜è¦"),
        QueryEngineTool.from_defaults(keyword_engine, description="æŸ¥è©¢é—œéµè©ç›¸é—œè³‡è¨Š"),
    ]

    return RouterQueryEngine(
        selector=LLMSingleSelector.from_defaults(),
        query_engine_tools=tools,
    )
```

---

### âœ… `app.py` (Streamlit)

```python
import streamlit as st
from router_engine import init_router_engine

st.set_page_config(page_title="æ³•è¦æŸ¥è©¢å°åŠ©æ‰‹", layout="wide")
st.title("æ³•è¦æŸ¥è©¢å°åŠ©æ‰‹ï¼ˆRouterQueryEngine ç‰ˆï¼‰")

query = st.text_input("è«‹è¼¸å…¥ä½ çš„å•é¡Œï¼š", value="ç¬¬5æ¢æ”¾æµæ°´æ¨™æº–æ˜¯ä»€éº¼ï¼Ÿ")

if query:
    with st.spinner("æŸ¥è©¢ä¸­..."):
        router_engine = init_router_engine()
        response = router_engine.query(query)
        st.markdown("### å›è¦†å…§å®¹")
        st.write(response)
```

---

### âœ… `data/` è³‡æ–™æ ¼å¼ç¯„ä¾‹ï¼ˆJSONï¼‰

æ¯ä¸€é¡å‹æ˜¯ä¸€å€‹ JSON é™£åˆ—ï¼š

#### `laws.json`

```json
[
    {"text": "ç¬¬5æ¢ï¼šæ”¾æµæ°´ä¸å¾—è¶…éæ¨™æº–..."},
    {"text": "ç¬¬6æ¢ï¼šæœ‰é—œæ‡²ç½°è¦å®šå¦‚ä¸‹..."}
]
```

#### `summaries.json`

```json
[
    {"text": "ç¬¬5æ¢çš„æ‘˜è¦æ˜¯é‡å°å·¥å» å»¢æ°´çš„æ¨™æº–..."},
    {"text": "ç¬¬6æ¢æ‘˜è¦èªªæ˜äº†ç½°å‰‡èˆ‡æ’æ”¾è²¬ä»»..."}
]
```

#### `keywords.json`

```json
[
    {"text": "é—œéµè©ï¼šæ”¾æµæ°´ã€æ‡²ç½°ã€ç½°å‰‡ã€æ±¡æ°´è™•ç†"}
]
```

---

é€™æ¨£ä½ å°±å¯ä»¥ä¾æ“šä¸åŒä¾†æºçš„åµŒå…¥å…§å®¹è‡ªå‹•æ‡‰ç­”ï¼Œé‚„èƒ½æ–¹ä¾¿æ“´å……èˆ‡æ¸¬è©¦ã€‚  
éœ€è¦æˆ‘ä¹Ÿå¹«ä½ åŠ å…¥ Ollama local LLM çš„ä¸²æ¥ï¼Œæˆ–æ˜¯ metadata filter çš„ç‰ˆæœ¬å—ï¼Ÿ

## Ollama local LLM çš„ä¸²æ¥

å¤ªå¥½äº†ï¼Œæˆ‘é€™å°±å¹«ä½ åŠ å…¥ï¼š

---

## âœ… åŠŸèƒ½æ“´å……ç›®æ¨™

1. **ä½¿ç”¨æœ¬æ©Ÿçš„ Ollama æ¨¡å‹**ï¼ˆä¾‹å¦‚ llama3-taide ç­‰ï¼‰é€²è¡ŒæŸ¥è©¢åˆ†æµèˆ‡å›ç­”  
2. **æ”¯æ´ metadata-based filtering**ï¼Œä¾‹å¦‚åªæŸ¥æŸç« ã€æŸæ¢ã€æŸé™„ä»¶ç­‰  

---

## âœ… ä¿®æ”¹é …ç›®èªªæ˜

### 1. **æ”¹ç”¨æœ¬æ©Ÿ Ollama ç•¶ä½œ LLM æ¨¡å‹**

æ›´æ–° `router_engine.py`ï¼š

```python
from llama_index.llms import Ollama

llm = Ollama(model="llama3-taide", temperature=0.1)
```

ç„¶å¾Œåœ¨ `RouterQueryEngine` ä¸­åŠ ä¸Šï¼š

```python
return RouterQueryEngine(
    selector=LLMSingleSelector.from_defaults(llm=llm),
    query_engine_tools=tools,
    llm=llm
)
```

---

### 2. **æ”¯æ´ metadata filteringï¼ˆç²¾æº–æ¯”å°ï¼‰**

ä½ çš„è³‡æ–™åœ¨å»ºç«‹æ™‚è¦åŒ…å« metadataï¼Œä¾‹å¦‚ï¼š

```json
{"text": "ç¬¬5æ¢ï¼šæ”¾æµæ°´ä¸å¾—è¶…æ¨™...", "metadata": {"æ¢": "ç¬¬5æ¢", "é™„ä»¶åç¨±": "æ”¾æµæ°´æ¨™æº–è¡¨"}}
```

å»ºç«‹ index æ™‚([./index_builder.py](#-index_builderpy))è¨˜å¾—å‚³å…¥ metadataï¼š

```python
from llama_index.core.schema import Document

def load_documents(json_path):
    import json
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    docs = [Document(text=item["text"], metadata=item.get("metadata", {})) for item in data]
    return docs
```

å»ºç«‹ [QueryEngine](#-router_enginepy) æ™‚ï¼Œæ”¹æˆå¯ä»¥æ”¯æ´ filterï¼š

```python
from llama_index.core.retrievers import VectorIndexRetriever
from llama_index.core.query_engine import RetrieverQueryEngine
from llama_index.core.indices.vector_store import VectorStoreIndex

retriever = VectorIndexRetriever(index=index, filters={"æ¢": "ç¬¬5æ¢"})
engine = RetrieverQueryEngine(retriever=retriever, llm=llm)
```

ä½ å¯ä»¥å†åŠ ä¸Šè‡ªå‹•åˆ¤æ–· metadata çš„å·¥å…·ï¼ˆæˆ‘ä¹‹å‰å¹«ä½ å¯«é `extract_keywords_from_query()` é€™é¡çš„å‡½å¼ï¼Œå¯ä»¥çµåˆé€²ä¾†ï¼‰ã€‚

---

### 3. **Streamlit ç•«é¢å¢åŠ  metadata æª¢æŸ¥é¸å–®ï¼ˆå¯é¸ï¼‰**

[app.py](#-apppy-streamlit)

```python
if st.checkbox("å•Ÿç”¨ Metadata ç²¾æº–ç¯©é¸"):
    selected_tiao = st.text_input("æŒ‡å®šæ¢æ–‡ï¼ˆä¾‹å¦‚ï¼šç¬¬5æ¢ï¼‰")
    selected_fujian = st.text_input("æŒ‡å®šé™„ä»¶åç¨±")

    filters = {}
    if selected_tiao:
        filters["æ¢"] = selected_tiao
    if selected_fujian:
        filters["é™„ä»¶åç¨±"] = selected_fujian

    response = router_engine.query(query, filters=filters)
else:
    response = router_engine.query(query)
```

---


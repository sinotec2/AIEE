

> 如果語言模型可以接受的Token數越長，微調的必要性是不是就越低？


---
layout: default
title: RAG Methodologies
parent: SearchingEngine
grand_parent: 自然語言處理
nav_order: 99
date: 2023-09-05
last_modified_date: 2023-09-05 13:44:37
has_children: true
permalink: /NLP/SearchingEngine/RAG_meth
tags: AI chat report
---

# RAG Methodologies 
{: .no_toc }

<details open markdown="block">
  <summary>
    Table of contents
  </summary>
  {: .text-delta }
- TOC
{:toc}
</details>
---

## 背景

> RAG 算是語言模型的訓練？還是微調？還是都不算？

RAG（Retrieval-Augmented Generation）算是一種在語言模型訓練過程中整合了檢索機制的方法，旨在改進生成的文本質量和相關性。RAG 結合了兩種主要的技術：語言模型和檢索系統。這種模型在處理每個查詢時，會先從一個大型的文檔集中檢索相關資訊，然後將這些資訊作為語言模型生成回答的一部分。

RAG 不單純是語言模型的訓練或微調，而是一種創新的方法，利用現有的語言模型和檢索技術的結合來生成回答。它通常使用已經訓練好的語言模型（如 GPT 或 BERT）和一個檢索系統，透過特定的結構將這兩者融合，以提升模型對於特定問題的理解和回答能力。

因此，RAG 可以視為在標準語言模型的基礎上，加入檢索機制來擴充模型的功能，使其在特定應用中表現更佳。这种结合让RAG在处理需要广泛背景知识的任务时，表现优于单独的语言模型。



## RAG vs finetuning

> 如果語言模型可以接受的Token數越長，微調的必要性是不是就越低？

語言模型能夠處理的 Token 數量越多，確實在某些方面可能降低微調的需求，但這並不是絕對的。模型處理更長的 Token 序列能夠帶來以下幾個好處：

	1.	更好的上下文理解：模型如果能夠接受更長的輸入，意味著它能夠一次考慮更多的信息，從而更好地理解上下文。這對於理解長篇文章、進行復雜的對話交互等情況特別有用。
	2.	降低資訊丟失：在較長的對話或文檔中，能處理更多的 Token 可以減少因截斷而導致的信息丟失。

然而，微調的必要性並不僅僅由能處理的 Token 數量決定：

	•	特定領域的專業知識：即使語言模型能夠理解較長的文本，對於需要特定領域知識的任務（如醫學、法律或特定行業的應用），微調仍然是必要的。微調能夠讓模型更好地適應這些特定領域的語言用法和知識。
	•	特定任務的性能提升：對於特定的應用或任務，如情感分析、問答系統等，即使模型可以處理更多的 Token，進行針對性的微調仍然可以進一步提升其性能，特別是在理解任務特定細節和語境上。

因此，能處理更多 Token 的模型在一定程度上可以減少對微調的依賴，特別是在不需要深入特定領域知識的通用任務中。但對於要求高精度或特定領域的應用，微調仍然非常重要。

## RAG 方法論

是的，RAG（Retrieval-Augmented Generation）存在著不同方法論的細節差異，這些差異主要體現在檢索機制、生成模型的選擇、以及檢索和生成部分的整合方式上。不同的實施方式可以根據應用場景和具體需求做出調整。

以下是 RAG 方法論中可能存在的細節差異：

1. 檢索方式的差異

	•	稀疏檢索 vs. 密集檢索：稀疏檢索（如基於 TF-IDF 或 BM25 的檢索）使用詞頻等傳統文本檢索技術，適合大規模的數據庫。密集檢索（如基於向量的檢索）則使用深度學習模型來將查詢和文檔映射到相似的向量空間中進行檢索，這種方法通常可以捕捉到語義上的相似性。
	•	單步檢索 vs. 多步檢索：在某些情況下，檢索不僅僅是一個簡單的查詢過程，可能需要多次迭代檢索來逐步找到更相關的資料，這也被稱為「檢索增強檢索」（retrieval-augmented retrieval）。

2. 檢索與生成的結合方式

	•	檢索後再生成：這是最常見的 RAG 模型方式，檢索到相關的文檔或片段後，將這些檢索結果作為上下文傳遞給生成模型，模型基於這些資料生成答案。
	•	檢索引導生成：有些實現方式會在生成過程中不斷進行檢索。例如，在生成答案的同時動態地檢索更多的相關信息，以保證答案與檢索結果高度一致。
	•	生成前的預處理：某些實施可能會先對檢索到的文檔進行一定的預處理或過濾，確保模型僅基於最相關的片段進行生成，從而提高生成的準確性。

3. 生成模型的選擇

	•	單一生成模型 vs. 多階段生成模型：RAG 可以使用單個生成模型來生成答案，也可以分成多個階段。例如，第一階段的生成模型根據檢索結果生成一個草稿，然後第二階段的模型進行精煉和修改。
	•	不同的生成架構：基於不同生成架構（如 GPT、BART、T5）的 RAG 系統也會在生成效果上有所不同。某些生成模型可能擅長長文本生成，某些則更擅長準確地生成具體答案。

4. 檢索文檔數量的設定

> RAG 是否存在著方法論的細節差異？

	•	不同的實現方式會根據具體任務選擇不同的檢索文檔數量。某些實現會檢索大量文檔，然後由生成模型選擇性地從中生成答案；而有些會限制檢索到的文檔數量，以提高效率。

5. 如何處理不相關或錯誤的檢索結果

	•	檢索到的文檔可能不總是完全相關或正確。某些 RAG 方法會設計篩選機制來過濾不相關的檢索結果，以提高生成答案的準確性。而其他方法可能會讓生成模型自動判斷哪些檢索結果應該被忽略。

6. RAG 模型的訓練策略

	•	在訓練 RAG 模型時，可以有不同的策略。有些實現會同時訓練檢索模型和生成模型，使兩者協同工作；而另一些實現則可能將兩部分獨立訓練，然後將它們組合在一起。

7. 應用場景的不同

	•	RAG 系統在不同應用場景中也會有不同的實現。
    例如，在問答系統中，RAG 的檢索重點是找到與問題**最相關**的文檔，而在生成新聞摘要等應用中，檢索部分則側重於找到最具**代表性**的信息來生成內容。

總結來說，RAG 的方法論可以根據具體的應用需求和技術選擇而產生差異，從檢索方法、檢索和生成的整合方式、到生成模型的架構，這些細節上的不同會影響 RAG 系統的最終性能。


